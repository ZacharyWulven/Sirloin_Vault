---
layout: post
title: 07-LangChain：多任务应用开发
date: 2025-08-10 16:45:30.000000000 +09:00
categories: [AI, AIStarted]
tags: [AI, AIStarted]
---


## LangChain：多任务应用开发

## LangChain 基本概念
* LangChain 提供了一套工具、组件和接口；简化了创建 LLM 应用的过程；可以理解为就是一个 workflow
* LangChain Memory：有记忆功能


### LangChain 六大组件：
1. Models 模型：比如 GPT-4o；对模型提供接口，帮你注册和管理很多模型
2. Prompts 提示：包括提示词管理、提示优化和提示序列化
    - PromptTemplate 是 LangChain 的提示词模板类
        - `chain = prompt | llm` 可以直接将 `prompt` 的输出作为 `llm` 的输入，形成一个可运行的链式结构，简化了原先 LLMChain 的写法
3. Memory 记忆：用来保存和模型交互时的上下文（对话记录）
4. Indexes 索引：用于结构化文档，方便和模型交互如果要构建自己的知识库，就需要各种类型文档的加载，转换，长文本切割，文本向量计算，向量索引存储查询等
5. Chains 链：一系列对各种组件的调用（Workflow）；例如，SQLChain
6. Agents 代理：决定模型采取哪些行动，执行并且观察流程，直到完成为止


### Agent 作用

![image](/assets/img/ai/start/lang_1.jpg)


### Tools
* 在 LangChain 中集成了一些常用的 tools，你也可以自定义自己的工具


#### [SerpAPI 工具](https://serpapi.com/manage-api-key)
* 支持 Google, Yahoo, Ebay, YouTube 等多种 API 查询
* `pip install google-search-results`
* 例如让 LangChain 可以使用 Serpapi 工具（Google搜索API）进行问题的解答
    - 例如：`query = 今天是几月几号?历史上的今天有哪些名人出生`


#### llm-math 数学运算工具使用
* llm-math工具: 给 Agent 提供数学相关的计算
    - 例如：当前温度的 0.5 次方是多少？

* 例如：当前北京的温度是多少华氏度，这个温度的 1/4 是多少？
    - Thinking：Agent 需要使用哪些 tools ？
        - Serpapi，搜索当前北京的温度
        - llm-math，计算这个温度的 1/4


### Memory 记忆（历史对话记录）
* Chains 和 Agent 之前是无状态的，如果你想让他能记住之前的交互，就需要引入内存
* 可以让 LLM 拥有短期记忆对话过程中，记住用户的 input 和中间的 output
* Memory 是针对 AI Agent
    - 每个用户的 AI Agent 实例不同 
    
    
    
#### 在 LangChain 中提供了几种短期记忆的方式：
1. BufferMemory：
    - 将之前的对话完全存储下来，传给 LLM
    - 适用于对话不多的场景

2. BufferWindowMemory：
    - 一般 LLM 记忆存储为 32k，大一点的 128k；超过了就不能用 BufferMemory
    - 最近的 K 组对话存储下来，传给LLM
    - 适用于对话很多，希望简单处理
    
3. ConversionMemory（核心是压缩成摘要）：
    - BufferWindowMemory 可能会丢失信息，所以可以用 ConversionMemory
    - `对对话进行压缩成摘要`，将摘要存储在内存中，相当于将压缩过的历史对话传递给 LLM
    - Langchain 中的 ConversationChain
    - Claude Code 就是用 ConversionMemory 策略
    - 适用于对话很多，需要压缩的场景

    
4. VectorStore-backed Memory：
    - 将之前所有对话通过向量存储到 VectorDB（向量数据库）中，每次对话，会根据用户的输入信息，匹配向量数据库中最相似的 K 组对话



## ReAct（Reason Act）范式
* ReAct: [Synergizing Reasoning and Acting in Language Models, 2022](https://arxiv.org/abs/2210.03629)
    - 将推理和动作相结合，克服 LLM 胡言乱语的问题，同时提高了结果的可解释性和可信赖度

* Thinking：作者对人类的行为的洞察：
    - 人们在从事一项需要多个步骤的任务时，在步骤和步骤之间，或者动作和动作之间，一般都会有推理过程


![image](/assets/img/ai/start/lang_2.jpg)

* 什么场景适合 ReAct 模式
    - 对于有一定复杂程度的问题，可以让 AI 自己进行探索
    


> Tips：可以设置思考的次数上限，例如最多 5 次，防止死循环
{: .prompt-info }


* Agent 的核心是把 LLM 当作推理引擎，让它能使用外部工具，以及自己的长期记忆，从而完成灵活的决策步骤，进行复杂任务
* LangChain 里的 Chain 的概念，是由人来定义的一套流程步骤来让 LLM 执行，可以看成是把LLM 当成了一个强大的多任务工具


### ReAct：是一种`思考-行动-观察`循环范式（Reasoning + Acting），即
1. 模型会先思考（Thought）
2. 再决定调用哪个工具（Action）
3. 然后观察工具的输出（Observation）
4. 再继续推理，直到得出结论


> ReAct 是思考模式，适用于复杂场景。ReAct 下大模型如何工作：思考 => Action Action Input => 观察 => 思考 ...；
LLM 自我对话：我要完成 XXX，我看到了 {tools}，我可以选择某一个 tool，传入 tool input，得到 tool 的 output
{: .prompt-info }


### 典型的 Agent 逻辑（比如 ReAct）：
1. 由 LLM 选择工具
2. 执行工具后，将输出结果返回给 LLM
3. 不断重复上述过程，直到达到停止条件，通常是 LLM 自己认为找到答案了



### AgentType.ZERO_SHOT_REACT_DESCRIPTION 模式

> Zero-Shot：指的是大模型在没有额外训练或示例的情况下，直接根据提示词（Prompt）和工具描述来推理如何调用工具（最常用）
{: .prompt-info }




## 工具链组合设计
* 在 Agent 系统中，工具链是实现复杂任务的关键组件。通过将多个工具组合，Agent 可以逐步处理复杂的问题。
    - 示例：LangChain 中的工具加载与组合
* 这里加载了搜索引擎工具（serpapi）和数学计算工具（llm-math），并将其与语言模型（LLM）组合使用，以处理需要搜索和计算的任务


> 即通过组合多个工具，让 LLM 调用，来解决复杂任务
{: .prompt-info }


### 整体的工作流程是怎样的？
1. 用户提交任务描述
2. Agent 分析任务，决定使用哪些工具
3. Agent 通过 ReAct 框架调用相应工具
4. 系统整合各工具结果，生成最终回答




## LCEL 构建任务链
* LCEL 是 LangChain 推出的链式表达式语言，支持用 `|` 操作符将各类单元（如 Prompt、LLM、Parser等）组合
* 每个 `|` 左侧的输出会自动作为右侧的输入，实现数据流式传递


### 优势：
* 代码简洁，逻辑清晰，易于多步任务编排
* 支持多分支、条件、并行等复杂链路
* 易于插拔、复用和调试每个子任务


### 典型用法：
* 串联：`A | B | C`，A 的输出传给 B，B 的输出传给 C
* 分支：`{"x": A, "y": B}`，并行执行 A 和 B
* 支持流式：如 `.stream()` 方法可边生成边消费




### LCEL VS ReAct
* ReAct: 是基于 LangChain 的 Agent 框架（如 create_react_agent、AgentExecutor 等），通过 Agent
结合工具链，自动解析用户输入，智能选择和调用合适的工具，支持多轮推理和工具调用。适合需要`智能决策+多工具自动调度`的复杂任务

* LCEL: 是基于 LCEL（LangChain Expression Language）表达式链式组合
    - 核心思想是用 LCEL 的 RunnableLambda 等方式，将各个工具函数以"数据流"方式串联或分支，手动调度任务链。适合需要"自定义流程、明确步骤、可控组合"的多工具任务
    - LCEL 任务链的每一步由开发者显式指定（如先文本分析再统计行数，或条件分支）。不具备 Agent 的`自主决策`能力，所有流程和分支都需手动编排



## AI Agent对比
1. 工作流编排
    - LangChain：线性链，适合固定流程任务（如文档问答）
    - LangGraph：支持循环、条件边和状态传递，适合动态调整的复杂逻辑（如多轮决策）
    - Coze：可视化工作流，支持嵌套和批处理，但灵活性较低
    - Dify：基于自然语言定义工作流，适合 API 集成和 Prompt 调优
    
2. 工具调用与扩展性
    - LangChain/LangGraph：工具作为链或图的节点，支持自定义工具和重试逻辑
    - Coze：依赖预置插件生态，扩展需通过开放平台
    - Dify：支持 OpenAPI 集成，适合技术栈复杂的场景
    
3. RAG（检索增强生成）
    - LangChain：开箱即用的文档加载、向量检索功能
    - LangGraph：需手动设计 RAG 节点，但支持反馈循环优化检索质量
    - Dify/Coze：Dify 提供基础 RAG 支持，Coze 依赖知识库管理

4. 多模态与部署
    - Coze：通过插件方式，支持图像、视频生成，可直接发布至社交平台
    - Qwen-Agent：开源架构，支持三级索引，以及工具调用，MCP 协议调用，使用方便
    - Dify：专注私有化部署，适合企业内网
    
5. AI Agent 选择建议：
    - 无代码开发： Coze
    - 快速原型开发：LangChain（线性任务）或 Qwen-Agent。
    - 复杂Agent系统：LangGraph（多 Agent 协作）或 Dify（API 深度集成）。
    - 企业私有化：Dify（开源部署）,Qwen-Agent 或 LangChain+LangGraph（灵活组合） 
    
    
    

## Q&A

### 1 LangChain、Dify、Coze 都是 AI Agent 搭建平台
* Dify、Coze 属于低代码
* LangChain 属于高代码


### 2 LangChain、LangGraph 是一家，LangGraph 是 LangChain 的升级版本
* LangGraph（图） 的能力 >= LangChain（线性的）


### 3 知识库更智能的回答？
1. Tool：不同需求，调用不同的 Tool，根据 query 和 tool description 之间的匹配进行调用
2. RAG：query => 与 RAG 中的 chunk 进行相似度匹配（基于 embedding）=> 选出 Top5 的 chunk 给 LLM 进行回答

### 4 Function Call
* LangChain 更早的提出了 Tool 调用，后来 OpenAI 把它集成到了大模型中，提供了这种能力


### 5 Tool 和 RAG 各自使用场景
RAG：就是知识库的场景，例如智能客服、问答
Tool：比较多，例如查天气，查新闻，计算数学题

### 6 Tool 是 Agent 的一部分
* Agent 是全集，是组装工厂，在工厂里 Tool 是重要的一环


### 7 fewshot 跟 ReAct 有什么关系
* fewshot 即小样本示例，给 LLM 作为 RAG 的上下文知识
    - 例如，可以用 fewshot 召回错题本
* ReAct 是思考模式，大模型如何工作：思考 => Action Action Input => 观察 => 思考 ...


### 8 ReAct 跟 CoT 思维连区别
* CoT 思维连，是事先定好的工作流程
* ReAct 是自主思考，利用自问自答方式，自己选择 tool


### 9 ReAct 是不是用非推理模型比较好
* 是的，推理模型幻觉高


### 10 如果 RAG 从知识库中多个 PDF 读取，比起单个 PDF 有什么需要注意点？
1. chunk 的 metadata（比如 源文件）比较重要
    - 例如：某个 chunk 是属于产品 A 
2. 召回策略


