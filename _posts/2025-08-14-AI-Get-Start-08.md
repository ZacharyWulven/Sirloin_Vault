---
layout: post
title: 08-Function Calling 与协作
date: 2025-08-14 16:45:30.000000000 +09:00
categories: [AI, AIStarted]
tags: [AI, AIStarted]
---


## Function Calling 与协作

## Function Calling 在大模型中的作用
* 扩展模型能力
  - 大模型本身无法直接操作外部系统（如数据库、计算工具），但通过调用预设函数，可以完成：
    - 实时数据获取（天气、股价、新闻）
    - 复杂计算（数学运算、代码执行）
    - 操作外部系统（发送邮件、控制智能设备）


* 结构化输出
  - 提取参数：`模型可将用户自然语言请求转化为结构化参数，传递给函数`。例如：
    - 用户说`明天北京天气如何？` => 模型调用 `get_weather(location="北京", date="2025-05-06")`


* 动态决策流程
  - 模型可根据上下文决定是否/何时调用函数，`甚至链式调用多个函数（如先查天气，再推荐穿搭）`


> `Function Call` 是大模型与真实世界交互的`桥梁`，从语言理解 => 具体行动
{: .prompt-info }



## Function Calling VS MCP

|维度|Function Calling |MCP
|定位|模型厂商私有接口（如OpenAI, Qwen）|开放协议（类似 HTTP/USB-C）
|扩展性 |需为每个模型单独适配|一次开发，多模型兼容
|复杂性 |适合简单、单次调用任务|支持多轮对话、复杂上下文管理
|生态依赖|依赖特定模型（如 GPT-4）|跨模型、跨平台（如 Claude、Cursor）
|安全性 |依赖云端 API 密钥|支持本地化数据控制

> MCP 会存一些状态，例如：会话 ID，会话上下文
{: .prompt-info }



## Thinking：已经有了MCP还需要 Function Calling 么？
### 简单、原子化任务使用Function Calling会更方便
* 查询天气 get_weather(city="北京")
* 计算数学公式 calculate(expression="3+5")
* 发送单条通知 send_email(to="user@example.com")
* 优势：
  - 开发快捷：无需配置 MCP Server，直接通过模型 API 调用预定义函数。
  - 低延迟：单次请求-响应，无需协议层开销。

> MCP 可能成为主流，但 Function Calling 作为底层能力仍将存在
{: .prompt-info }



## Qwen3
* 包含 8 种不同规模的模型
  - 涵盖密集（Dense） 和混合专家（MoE） 架构
  - 全部基于Apache 2.0 开源协议，支持免费商用
  
* MoE 模型（高效推理）：
  - Qwen3-235B-A22B（总参数 2350 亿，激活 220 亿）—— 旗舰级模型，性能接近 Gemini 2.5 Pro
  - Qwen3-30B-A3B（总参数 300 亿，激活 30 亿）—— 高效推理，仅需 10% 激活参数即可超越前代 QwQ-32B
* 密集模型（全参数激活）：
  - Qwen3-32B、14B、8B、4B、1.7B、0.6B，其中 Qwen3-4B 性能媲美前代 Qwen2.5-72B


> 国内可以用 Qwen 8B 或 32B
{: .prompt-info }



## Function Call 两种方式
* 方法1：大模型调用 Function Call
  - Step1：大模型给你调用方法，比如 `tool_call=xxx`
  - Step2：看到返回的 function name 和 function arguments，将参数解析出来传入到函数中运行，得到结果

* 方法2：Qwen-Agent


## Qwen-Agent
* 即一堆 Agent 的管理工具
* `pip install -e ./"[gui,rag,code_interpreter,mcp]"`
  - gui：图形化界面
  - rag：RAG 知识库
  - code_interpreter：代码解释器，帮你执行 Python 代码
  - MCP：模型上下文协议


### 搭建流程
* Step1：系统初始化
  - 设置系统 prompt，描述门票表结构和常见查询需求
  - 注册 SQL 查询工具（exc_sql），用于执行数据查询
* Step2：助手实例化
  - 使用 Qwen-Agent 的 `Assistant` 类，加载 LLM 配置、系统 prompt 和 function_list（只包含 exc_sql）
    - `Assistant` 类是最常用的
* Step3：设置交互模式
  - 选择 WebUI 模式，用户通过网页输入问题，助手自动完成 SQL 查询并返回结果，右侧可列出常见问题
* Step4：Function Call 机制
  - 用户输入自然语言问题
  - LLM 解析意图并自动生成 SQL 查询语句
  - exc_sql 工具被自动调用，执行 SQL 并返回查询结果
  - 结果通过终端或 WebUI 展示给用户


### GUI 
* 基于 Gradio（开源 web 页面）
* Python 中两个 GUI 常用框架
  - Gradio
  - Streamlit
  
  
> 可以把 Qwen-Agent 代码复制到工程进行自定义，例如：修改 GUI 相关
{: .prompt-info }


### 如何发布 Qwen-Agent 让别人用
* 方法 1：`WebUI(bot, chatbot_config=chatbot_config).run(share=True)`
* 方法 2：部署到服务器，`server_name=0.0.0.0` `server_port=你指定的服务器端口，例如 9001`



## Function Call 的微调 (了解即可)
* 通常大模型具备 Function Call 的能力，但有时候针对特定的 Function Call 理解和提参能力不强
* 可以微调 Function Call 的微调目标，是教会模型下面两件事：
  1. 判断是否需要调用函数（比如`查天气`需要，而`写首诗`不需要）
  2. 正确提取参数并生成格式化的调用指令（比如转成 JSON）



### 微调的步骤是怎样的？
* Step1：准备数据
  - 输入：用户问题（如`北京今天天气？`）
  - 函数描述：告诉模型有哪些函数可用（比如 get_weather(city, date)）。期望输出：
    - 需要调用时：生成 JSON 格式的函数调用（如 `{"name":"get_weather", "arguments":{"city":"北京", "date":"今天"}}`）
    - 不需要时：直接生成回答（如`你好，今天星期一...`）
* Step2：模型训练
  - 选一个擅长理解指令的预训练模型，如 Qwen
  - 用上述数据训练模型，让它学会`根据问题和函数描述，决定是否调用函数，并生成正确格式`


### Function Call 微调的关键点
* 数据质量：
  - 数据质量要好
    - 需覆盖各种场景（需要/不需要调用、参数变化等）
    - 除了正样本也要给一些不需要调用函数的负样本的案例
* 函数描述要清晰：模型靠描述理解函数用途
* 避免误触发：加入足够多`无需调用`的样本，防止模型滥用函数





![image](/assets/img/ai/start/lang_1.jpg)







## Q & A

### 1 想搭建一个基于公司产品手册的知识问答，公司每个系列产品都有一个手册，每个手册都创建一个 db 吗?
* 可以，一个产品一个知识库，可以更有效的筛选知识库


### 2 画图工具
* 文本大模型 => 写代码（生成 matplotlib 图表，或者生成 echarts 图表）

