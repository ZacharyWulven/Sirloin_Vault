---
layout: post
title: 01-AI 大模型基本原理及 API 使用
date: 2025-07-11 16:45:30.000000000 +09:00
categories: [AI, AIStarted]
tags: [AI, AIStarted]
---


## AI 大模型基本原理及 API 使用

## AI的核心目标
* 是让机器能够执行通常需要人类智能的任务，例如语言理解、图像识别、复杂问题解决等
    - 早期阶段：以规则为基础的专家系统，依赖预设的逻辑和规则。
    - 机器学习时代：通过数据训练模型，使机器能够从数据中学习规律。
    - 深度学习时代：利用神经网络模拟人脑的复杂结构，处理更复杂的任务。
    - 大模型时代：以大规模数据和算力为基础，构建通用性强、性能卓越的 AI 模型


## AI 的分类

### 分析式 AI（决策）
1. 也称判别式 AI，其核心任务是对已有数据进行分类、预测或决策
2. 优势在于其高精度和高效性，但其局限性在于仅能处理已有数据的模式，无法创造新内容

### 生成式 AI（创造）
1. 专注与创造新内容，例如文本、图像、视频
2. 突破在于其创造性和灵魂性，但也面临数据隐私、版权保护等挑战


## 大语言模型（LLM，Large Language Model）

### 1 大语言模型 
* LLM 是基于海量文本数据训练的深度学习模型，属于生成式 AI 的一种。它能理解和生成类人类的自然语
言，常见模型如 GPT 系列、DeepSeek, Qwen 等。
* 具备强大的文本理解、摘要、翻译、问答及内容创作能力。通过上下文关联，能进行连贯且富有逻辑的对话与写作。并且通过少量示例可以进行下游任务的学习。
* 场景示例：
    - 智能客服： 电商网站导入基于 LLM 的聊天机器人，能即时理解客户复杂的售后问题，提供个性化的解决方案，大幅提升服务效率与客户满意度。
    - 内容创作： 营销团队使用 LLM，输入产品关键字和目标受众，快速生成多版本的广告文案、社交媒体帖文与博客文章，有效降低人力成本。


### 2 生图、生视频
* 专门将文字描述转换为全新的图像或视频。它们学习了图像、视频与其对应文字标签之间的关联，代表模型有 DALL-E、Midjourney 及 Sora。
* 能够根据用户输入的 `文字提示（Prompt）`，创造出符合描述且风格多样的视觉内容。模型能融合不同概念、属性和风格，生成前所未有的原创作品。
* 场景示例：
    - 产品设计： 设计师输入`一款具有未来感的流线型运动跑鞋，采用回收海洋塑料材质`，模型可快速生成多款概念图，加速产品可视化与迭代过程。
    - 影视预览： 导演利用文字生成视频模型，将剧本中的关键场景转换为动态预览片段，以便在实际拍摄前，评估镜头、光影和场景布局的可行性。

#### 生图网站
1. [liblib](https://www.liblib.art)
2. [即梦](https://jimeng.jianying.com)


### 3 视觉识别模型(Computer Vision Model)
* 视觉识别模型让计算机能`看懂`并解析图像与视频内容，属于计算机视觉领域。主要任务包括图像分类、物体检测、图像分割等，模型如 YOLO、ResNet。
* 能准确辨识影像中的物体、人脸、文字或特定场景。其核心在于从像素中提取特征，并与已知模式进行比对，以完成识别、定位或追踪等任务。
* 场景示例：
    - 智能制造： 在生产线上部署视觉识别系统，能即时检测产品外观的微小瑕疵，如刮痕或缺件，自动剔除不合格品，确保出厂品质，准确率远超人眼。
    - 医疗影像分析：医院导入 AI 辅助判读系统，分析 X 光或 CT 扫描影像。模型能快速标记出疑似肿瘤或病变的区域，协助放射科医生提高诊断效率与准确性。


### 4 自动驾驶模型（Autonomous Driving Model）
* 一套复杂的AI系统，整合了视觉识别、传感器融合、决策规划等多种模型。其目标是让车辆在无需人类干预下安全行驶，是AI技术的高度整合应用。
* 通过摄像头、激光雷达(LiDAR)等传感器，即时感知周遭环境，识别行人、车辆与交通标志。模型会预测其他物体的动态，并规划出最佳的行驶路径与操作。
* 场景示例：
    - 无人配送：物流公司采用自动驾驶货车，在特定园区或高速公路进行货物运输。系统能自主导航、避开障碍物并遵守交通规则，实现 24 小时不间断的物流运作。
    - 高级辅助驾驶：现今许多市售车辆搭载的辅助驾驶系统，能在高速公路上自动跟车、维持车道居中。
    这背后就是自动驾驶模型在识别车道线与前车距离，并控制方向盘与加减速。


### 5 大语言模型
* 大语言模型是一种通用自然语言生成模型，使用大量预料数据训练，以实现生成文本、回答问题、对话生成等
* 基本能力
    -   语言生成
    - 上下文学习
    - 世界知识
    
* `超`能力
    - 响应人类指令
    - 泛化到没有见过的任务
    - 代码生成和代码理解
    

## ChatGPT 是如何训练出来的？

![image](/assets/img/ai/start/how_tow_train.png)

> Step1（监督学习）相当于从 0 分直接到了 60 分对事物有些概念，然后在不断创作、不断创作，最终得到更好的答案
{: .prompt-info }

![image](/assets/img/ai/start/how_tow_train2.png)

> Rank List 就是人给机器打标记
{: .prompt-info }

### ChatGPT 优势

![image](/assets/img/ai/start/gpt_ad.png)


> 1TB 语料等于 1000 万本书。
{: .prompt-info }


## 不同语言模型的 Token 都是如何定义的（重要）

* Token（分词） 是大型语言模型处理文本的最小单位
* 由于模型本身无法直接理解文字，因此需要将文本切分成一个个 Token，
再将 Token 转换为数字（向量）进行运算。不同的模型使用不同的`分词器（Tokenizer）`来定义 Token。
    - 例如，对于英文 Hello World：GPT-4o 会切分为 ['Hello', 'World'] => 对应的 token id = [13225, 5922]
    - 例如，对于中文`人工智能你好啊`：DeepSeek-R1 会切分为 ['人工智能', '你好', '啊'] => 对应的 token id = [33574, 30594, 3266]
        - 中文按照单词方法划分 Token

* 分词方式的不同会直接影响模型的效率和对语言细节的理解能力。可以通过 [Token 转换网站](https://tiktokenizer.vercel.app/) 这个工具看到不同模型是如何切分你输入的文本的。

## 模型的常见特殊 Token
* 为了让模型更好地理解文本的结构和指令，开发者会预设一些具有特殊功能的 Token。
* 这些 Token 不代表具体词义，而是作为一种`标点`或`命令`存在。

1. 分隔符 (Separator Token): 用于区分不同的文本段落或角色。比如，在对话中区分用户和 A I的发言，可能会用 `<|user|> 和 <|assistant|>` 这样
的 Token。

2. 结束符 (End-of-Sentence/End-of-Text Token): 告知模型文本已经结束，可以停止生成了。常见的如 `[EOS] 或 <|endoftext|>`。这对于确保模型生成完整且不冗长的回答至关重要。

3. 起始符 (Start Token): 标记序列的开始，例如 `[CLS] (Classification) 或 [BOS] (Beginning of Sentence)`，帮助模型准备开始处理文本。


![image](/assets/img/ai/start/sp_token.png)


## 大模型的 Temperature、Top P 的原理与作用
* `Temperature 温度` 和 `Top P 核采样` 都控制 LLM 生成文本的多样性，但原理不同。


### Temperature 温度
* 原理: 在模型计算出下一个 Token 所有可能的概率分布后，Temperature 会调整这个分布的`平滑度`
    - 高 Temperature (如 1.0+): 会让低概率的 Token 更容易被选中，使生成`结果更具创造性，可能出现不连贯的词语`。
        - 想让其活跃 可以让 Temperature 高一点
    - 低 Temperature (如 0.2): 会让高概率的 Token 权重更大，使生成`结果更稳定、更符合训练数据，但会更保守`。
        - 想更稳定可以让 Temperature 低一点
        - 低概率不容易被选择，但可以把它激活


### Top P 核采样（类似一个 filter）
* 原理: 它设定一个概率阈值（P），然后从高到低累加所有 Token 的概率，直到总和超过 P 为止。模型只会在这个累加出来的`核心`词汇表中选择下一个 Token。
    - 高 Top P (如 0.9): 候选词汇表较大，结果更多样。
    - 低 Top P (如 0.1): 候选词汇表非常小，结果更具确定性。
* 假设模型要完成句子：“今天天气真...”。 模型预测的下一个词可能是：好(60%)、不错(30%)、糟(9%)、可乐(0.01%)。
    - 高 Temperature：`会提升所有词的概率`，使得`可乐`这个不相关的词也有机会被选中。
    - 高 Top P (设为0.9)：`会选择概率总和达到 90% 的词`。这里 好(60%) + 不错(30%) = 90%，所以模型只会从`好`和`不错`中选择，直接排除了`可乐`这种离谱的选项。


> 相比 Temperature，Top P 能更动态地调整候选词的数量，避免选到概率极低的离谱词汇 => 产生更高质量的文本。
{: .prompt-info }


## AI大模型聊天产品的 `超能力`

### 超能力1：联网搜索（网上的）
* 弥补 LLM 训练数据截止日期的限制 => 获取外部信息(Function Call)
    - 当用户提问涉及最新资讯时，系统会识别出这一需求，自动调用搜索 Tool，并将问题转化为多个简洁的搜索关键词。
    - 接着，程序调用搜索引擎 API（如 Google 搜索）获取信息。(联网搜索会输入一个关键词)
    - 最后，这些实时信息会作为上下文提供给模型，由模型进行总结和提炼，生成精准且与时俱进的回答。
    - 例如，当你询问`黄金的涨跌和哪些因素有关?` LLM 会调用一个搜索工具，输入你刚才的问题，然后获取相关的信息 => 整理到回答中。


> 提参：`Function Call` 时会传参数，是从用户的问题中提取的。如果大模型提参能力不好可以 `fine tune`
{: .prompt-info }


### 超能力2：读取文件（本地化，比如企业知识库）

> 给大模型的数据源至关重要，所以企业内部需要 RAG 搜索，所以我们会把我们的数据专门整理起来，利用大模型的读取文件能力
{: .prompt-info }

* 基于`检索增强生成（Retrieval-Augmented Generation, RAG）`的技术。
    - 当你上传一个文件（如 PDF、Word 文档）时，系统首先会将其内容分割成小块（Chunks）。
    - 然后，通过 Embedding 技术将这些文本块转化为数学向量，并存储在专门的`向量数据库`中。
    - 当你针对文件内容提问时，系统会将你的问题也转化为向量，并在数据库中快速找到最相关的文本块
    - 最后将这些文本块连同你的问题一起交给模型，生成答案。
    - 例如，上传一份公司财报后，提问`第二季度的利润是多少？`RAG 系统能精确定位到财报中相关的片段，让 LLM 直接使用。


> Chunks Size 比较重要，Qwen 模型一般设置在 500 左右。如果知识连贯性很强可以设大点，如果知识很碎可以设小一点。
{: .prompt-info }


### 3 记忆功能(从金鱼到伙伴)
* LLM 本身是无状态的，每次对话都是一次全新的互动，不记得之前的交流。为了实现`记忆`，系统会在每次对话时，将最近的几轮问答作为背景信息一起发送给模型
称为 `短期记忆 或 上下文窗口`。
* 对于需要长期记住的关键信息
    - 例如你的名字或偏好，系统会通过特定算法提取这些信息，将其存储在用户专属的数据库中。
    - 在后续的对话中，系统会先从数据库中读取，为模型提供更个性化的背景知识。
    - 比如，你告诉 AI `我喜欢简洁的回答风格`，系统会记录这一偏好。下次你提问时，它就会倾向于给出更简练的答复。



## 安全审核
* 各国都有安全审核，比如国外企业不可能用 `Deepseek`。Vice versa


## 中国AI公司概览
* 大科技公司：
    - 阿里巴巴：通义千问（Qwen）系列，Qwen3
    - 百度：文心一言（Ernie 4.0 Turbo）
    - 腾讯：混元大模型（Hunyuan Large）
    - 字节跳动：豆包（Doubao 1.6 Pro）
    - 华为：盘古 5.0（Pangu 5.0 Large）
* 初创公司：
    - DeepSeek：R1、V3，开源模型表现优异。
    - Moonshot：Kimi K2，专注长上下文窗口。
    - MiniMax：Text-01，多模态能力突出。
    - 其他：智谱 AI（ChatGLM）、百川智能（Baichuan）等。


## API 使用
* 申请 API_Key 在 [阿里云百炼](https://bailian.console.aliyun.com/#/home) 
* 百炼 API_Key 模型推荐 `qwen-turbo/deepseek-v3/deepseek-r1`
* 一般使用 `Qwen-Turbo` 就行，性价比高
* Function Call 可以使用 `Qwen-Max`


### 表格提取模型选择
1. Qwen-VL（基础模型）: 核心能力：支持图像描述、视觉问答（VQA）、OCR、文档理解和视觉定位
2. Qwen-VL-Chat（指令微调版）: 基于Qwen-VL进行指令微调（SFT），优化对话交互能力
3. Qwen-VL-Plus / Qwen-VL-MAX（升级版）: 性能更强，接近 GPT-4V 水平，但未完全开源
4. Qwen2.5-VL（最新旗舰版）模型规模：提供3B、7B、72B版本，适应不同计算需求


### 系统提示词 (System Prompt)
* 用于设定 AI 的角色、行为准则和输出格式，是贯穿对话的全局指令，为其提供了扮演的`人设`
* 应在对话开始时设定，内容要清晰明确。
* 它会像普通问题一样消耗 Token，不应在其中包含用户的具体问题。频繁更改可能导致AI行为不稳定。

### 与大模型交互的 Role 
1. system：系统提示词, 设定 AI 的角色
2. assistant：AI 以助手角色返回的
3. user：用户提示词
4. tool: 工具返回的结果


### LLM 的输入与输出 Token 限制
* 模型单次 API 调用能处理的最大信息量，包含系统提示词、历史对话和当前用户输入的所有内容。
* 所有输入内容的总长度不能超过此限制，否则 API 会报错。
* 我们需自行管理历史对话长度，比如通过截断或总结旧消息来确保请求不超过上限。
* 假设某模型上限为 4096 Token(Context Window)。如果此时系统提示词和历史对话已占用 3500 Token
    - 那么用户提示词长度不能超过 4096 - 3500 = 596 Token

### 输出 Token 限制
* 输出 Token 限制: 指模型在一次回复中能生成的最大内容长度。
* 我们通常可以在 API 请求中手动设置此参数（如 `max_output_tokens`）。
* 设置过低会导致回答不完整，内容被突然截断；
* 设置过高则可能增加 API 调用时间和费用。需要根据具体任务需求权衡。
    - 如果你请求模型写一首诗，但将输出限制设为 5 Token，那么可能只会得到诗的第一句，后面内容会被截断。
* `max_output_tokens` 只是截断，大模型写了很多，只是按照你的 `max_output_tokens` 截断返回给你
